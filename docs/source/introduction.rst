************
Introduction
************
This book presents Common Student Errors (CSEs) that have been made by first year students taking Engineering Mathematics e-examinations at the University of the West of England, Bristol (UWE, Bristol). The CSEs presented in this document were collected from 2017-2019 as part of the Common Student Errors Project (CSE Project at UWE) conducted at UWE, Bristol. This research has been conducted by Indunil Sikurajapathi for her Doctoral studies under the guidance of Dr Karen Henderson and Dr Rhys Gwynllyw.

This book is organised as follows. In Section 1.1 and Section 1.2 we present a brief background of Common Student Errors (CSEs) and the Dewis e-Assessment System. Then we explain how we conducted the CSE Project at UWE, Bristol in Section 1.3 and the present the CSEs Collection found during the project in Section 1.4. The taxonomy coding utilised to classify the CSEs in e-Assessments found in this project is discussed in detail in Section 1.5. After that we provide a Guide to the CSE recording template in Section 1.6 which is used in the subsequent Sections 2-23 to present all of the 65 CSEs found to date during the CSE Project at UWE, Bristol.

One of the special features of this book is that it provides hyperlinks to each question on the Dewis e-Assessment System in order to facilitate the reader to try these questions online. If any of the identified CSEs are submitted as answers, then enhanced feedback will be provided, which aims to correct any misconceptions in a timely manner.

The information in this book may be used to inform teachers so that they can provide students with a better understanding of the mathematical skills and knowledge while teaching the subject. It may also be useful for institutions as they can utilise it in the future development of teaching materials to ensure that these CSEs will be addressed. Further, the content of this book can be used to develop support materials and resources to address CSEs which will help students to acquire better understanding of mathematics. In addition, students who learn mathematics at university level or in secondary school can refer to this booklet to address their misconceptions and can try the Dewis questions several times. Since, in each attempt, Dewis produces questions with random parameters, student can use this facility to correct their misconceptions by practicing the same question but with different parameters.


We anticipate that this book will be useful to identify and address some misconceptions that students have in mathematics. We plan to continue with this research and will update the book if we find new CSEs in the future.

Common Student Errors (CSEs)
############################
Students arrive at an incorrect answer when answering a mathematical question due to variety of reasons. The reasons can be listed as random errors, calculation errors or misreading the questions. These errors lead to incorrect answers or loss of accuracy marks. Many of these errors are made by just a few students. However, some of these errors are commonly made by a considerable number of students. These commonly made errors are sometimes referred to as common errors (Rushton, 2014).

Researchers express different opinions about the difference between errors and misconceptions in the literature. For Confrey (1990), the reasons for both errors and misconceptions are the rules and beliefs that students hold. They argue that the difference between errors and misconceptions is that misconceptions are attached to particular theoretical positions. However, Nesher (1987) uses the term misconceptions to describe systematic errors without reference to a theoretical position.

Rees and Barr (1984) use the term ‚Äòmal-rule‚Äô to refer to an understandable but incorrect implementation of a process resulting from a student‚Äôs misconception. For example, a classic mal-rule students make is to answer ùëé2+ùëè2 when asked to expand (ùëé+ùëè)2. The term ‚Äòbug‚Äô is used by VanLehn (1982) to refer to a systematic error resulting from wrong steps in the calculation procedure. A Borrow Across-Zero bug is a systematic error caused by a student having trouble with borrowing, especially in the presence of zeros (VanLehn, 1982). For example, a student answering 98 when asked to calculate 305‚àí117 would be considered as a Borrow Across - Zero bug. In the aforementioned calculation, the student skips the step where the zero changed to nine during borrowing across zero (VanLehn, 1982).
Research has been conducted to identify misconceptions in different areas of mathematics. For example, Brown and Burton (1978) investigated bugs (misconceptions) in high school algebra problems, and Swan (1990) focused on the misconceptions that occur in four operations (addition, subtraction, multiplication and division), and in the interpretation of graphs.

Some Mathematics Education research has explored possible causes and effects of certain mathematical misconceptions and the impact that they have on students‚Äô future learning (Booth et al., 2014; Confrey, 1990; Fischbein, 1989; Nesher, 1987; Brown and Burton, 1978). After having investigated bugs (misconceptions) in high school algebra problems, Brown and Burton (1978) discussed possible arithmetic bugs which might lead to some specific algebraic bugs. Booth et al., (2014) conducted a study to assess algebraic misconceptions that algebra students make at school. They concluded that students who make specific persistent errors due to underlying misconceptions in arithmetic may need additional intervention since misconceptions are not corrected through typical instruction. They conclude that these additional interventions can be carried out by targeting individual misconceptions or by improving conceptual understanding throughout the algebra course. The findings of Brown and Burton (1978) and then the findings of Booth et al. (2014) hold the same conclusions, that the arithmetic misconceptions held by students affect their algebraic thinking. Further, Booth et al. (2014) state that these arithmetic misconceptions can obstruct their performance and learning of algebra.

There has been recent research into theorising student errors supported by empirical studies in the topics of natural number bias (Obersteiner et al., 2013), visual saliency (Kirshner and Awtry, 2004) and over-generalisation (Knuth et al., 2006). Rushton (2014) conducted a study of common errors in Mathematics made in certain General Certificate of Secondary Education mathematics papers taken by candidates in England, including an internationally available version, as referenced by examiner reports, and errors were catalogued into themes and subthemes. More recently, Ford et al. (2018) developed a taxonomy of errors made by undergraduate mathematics students. In their study they gathered errors by firstly recalling the most obvious errors that occur and secondly by analysing students‚Äô exam scripts to categorise them in a taxonomical manner.

Dewis e-Assessment System
#########################
Dewis is a fully algorithmic open-source e-Assessment system, which was primarily designed and developed for numerate e-Assessments by a team of Mathematicians, Statisticians and Software Engineers at UWE Bristol (Gwynllyw and Henderson, 2009; Gwynllyw and Henderson, 2012). Dewis supports different question input types such as numerical inputs, matrices, vectors, algebraic expressions, multiple-choice, multiple-selection, graphical input, and computer programs. It has a lossless data collection feature and a number of student-friendly features, such as shutdown recovery and pre-processing checks on student input.

Over the past decade, Dewis has been used very successfully to facilitate both formative and summative e-Assessments across a number of modules, delivered to students in a wide range of fields, e.g. Business, Computer Science, Nursing, Software Engineering, Engineering, Mathematics and Statistics. One aim of the CSE project is to enhance the full potential of Dewis, by developing and using additional features allowing Dewis to detect CSEs and to provide instant tailored feedback.

The Common Student Errors Project at UWE, Bristol
#################################################
The CSE project at UWE began in 2017 with an aim of developing a technique to detect CSEs and to provide tailored feedback in Dewis e-Assessment questions, used in a first year Engineering Mathematics module (CSE Project at UWE, 2019; Sikurajapathi, Henderson and Gwynllyw, 2020; Sikurajapathi, Henderson and Gwynllyw, 2021). We started the project with the aim of answering the following research questions:
*What CSEs do first year Engineering Mathematics students make in e-Assessment questions?
*How to detect CSEs and improve Dewis feedback to address these CSEs?
There are several benefits to answering these research questions. Even though this research has been done in a particular context using the Dewis e-Assessment system, the research outcomes contribute to the knowledge to inform more general practice in assessment and learning. For example, the collection of mathematical CSEs collected during this research is not only beneficial for first year Engineering mathematics students and lecturers, but also it is equally beneficial for secondary, and first year university level mathematics students and teachers. The CSE collection presented in Sikurajapathi, Henderson and Gwynllyw (2022) can be used to correct students‚Äô mathematical misconceptions either in hand-written assessments or e-assessment questions.

Further, this CSE detecting technique will be beneficial to several disciplines and organisations that either use Dewis or any other e-assessment system which has features to give dynamic feedback based on a student answer. The new knowledge raised from this research can be used in any e-assessment system so that it emulates a human marker to provide instant enhanced feedback highlighting possible CSEs. This will help students to correct their mathematical misconceptions. Also, teachers can use the findings to identify areas in which more help is needed in student learning. Integrating the research outcomes from the CSE project into other e-assessment systems will be beneficial to generations to come (Sikurajapathi, Henderson and Gwynllyw, 2020; Sikurajapathi, Henderson and Gwynllyw, 2021; Sikurajapathi, Henderson and Gwynllyw, 2022).

The CSE Project involves five stages (Stage One: Data (CSEs) Collection; Stage Two: CSE code Development; Stage Three: CSE code Trial Phase; Stage Four: Students‚Äô Perceptions on CSE Feedback and Stage Five: Impact of CSE Project). Detailed information about these five stages and other findings can be found in CSE Project at UWE Bristol (2019), Sikurajapathi, Henderson and Gwynllyw (2020) and Sikurajapathi, Henderson and Gwynllyw (2021).

In this book, we only focus on Stage One: Data (CSEs) Collection, which provides an answer to the question ‚ÄòWhat CSEs do first year Engineering Mathematics students make?

Common Student Error Collection
###############################
The CSEs presented in this booklet were collected by examining the 2017-2018 and 2018-2019 e-examination data on the Dewis e-Assessment system and from students‚Äô rough work scripts. These e-examinations were run using the Dewis e-Assessment system and were held under controlled conditions. The e-examinations were held in two sessions (morning and afternoon) to mitigate logistic issues. In each session, all of the students received the same, fixed parameter questions. During the e-examination, students were given booklets to use for their rough work. These booklets were used by students to work through the mathematical questions before submitting their final answers on Dewis.

Altogether 65 CSEs were identified in the following different topics areas of Engineering Mathematics:
*Algebra
*Unit-step function
*Wave forms
*Trigonometric functions
*Differentiation
*Implicit differentiation
*Partial differentiation
*Mean Value Theorem
*Complex numbers
*Geometric series
*Maclaurin Expansion
*Centre of Mass
*Integration by parts
*Volume of revolution
*Dimensions

Taxonomy of Mathematical Common Student Errors in e-Assessments
###############################################################

All of the CSEs found in the course of the CSE project are documented in a systematic order in the CSE book together with their mathematical taxonomy coding. Here we used the taxonomy coding described in Ford et al. (2018) as a guideline.

The theoretical study of classification, including its bases, principles, procedures and rules is called a taxonomy (Ford et al., 2018; Simpson, 1961, p.11). The entities in a successful taxonomy can be verifiable by observation and will offer both an appropriate and suitable class for each entity (Ford et al., 2018; Bailey, 1994, p.3). The taxonomy of cognitive mechanisms and the phenomenological taxonomy can be considered as the two main styles that can be used to categorise mathematical errors (Senders and Moray, 1991, Ford et al., 2018).

The taxonomy introduced by Ford et al. (2018) was developed to categorise the errors which undergraduate mathematics students make. Ford et al. (2018) identified six main error categories by firstly recalling obvious mathematical errors that occur among mathematics undergraduates and secondly by analysing a selection of students‚Äô paper-based exam scripts from first year undergraduate mathematics courses. These main categories were named as Errors of slips of action (S), Errors of understanding (U), Errors in choice of method (CM), Errors in the use of a method (UM), Errors related to proof (P), and Errors in student‚Äôs communication of their mathematical solutions (C).

The CSEs that we have found during the CSE project only fall into four of the error categories (S, U, CM and UM) from the Ford et al. (2018) taxonomy. Errors related to proof (P), and Errors in student‚Äôs communication of their mathematical solutions (C) were not found among the CSEs made by the Engineering Mathematics students, due to the nature of the questions asked and the nature of the system used to deliver the questions. None of the e-Assessment questions

delivered by Dewis involve mathematical theorems and proofs and hence Errors related to proof (P) were not viable in this CSE collection. Further, the e-examination did not contain questions that required student‚Äôs communication of their mathematical solutions, correct use of notation or labelling and qualitative judgements on clarity of expression. Therefore, errors in student‚Äôs communication of their mathematical solutions (C) were not found in this CSE collection. Further, a few of the CSEs found fall into two categories due to the mix of misconceptions made by the students as they arrived at their incorrect answer.

Under the category Errors of slip of action (S), three main errors, namely copying error, careless errors on simple calculations, and incorrect algebraic manipulation were identified. A total of 13 out of 65 CSEs were found to fall into the Errors of slip of action category (S).

Seven main errors were identified under the Errors of understanding (U) category, such as confusing different mathematical structures, incorrect argument, lack of consideration of potential indeterminate forms, proposed solution is not viable, definition/method/theorem not recalled correctly, partial solution given and Incorrect assumptions. In total 45 CSEs are in the Errors of understanding category.

Only one main error was found in each of the Errors in choice of method (CM) and Errors in use of method (UM) categories. Three CSEs were grouped into the main error of applying an inappropriate formula/method/theorem in CM. There were 9 CSEs which fell into Error in use of an appropriate definition/method/theorem in the UM category. All the codes, errors and examples that we found in this CSE collection process are shown in Table 1.

+---------------+------+-------+------------+
| Main Category | Code | Error | Examples   |
+===============+======+=======+============+
| Main Category | Code | Error | Examples   |
+---------------+------+-------+------------+



